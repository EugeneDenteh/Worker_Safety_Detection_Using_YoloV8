{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsME4yMFnr06",
        "outputId": "7fd5aa35-423f-4c49-a855-b3742d011b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5iDLbvlrRhv",
        "outputId": "dd223227-4c01-4188-93c5-758973301908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.20\n",
            "  Downloading ultralytics-8.0.20-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.66.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.14.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.20)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk (from ultralytics==8.0.20)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.20) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2023.11.17)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (2.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->ultralytics==8.0.20)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.9.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.20) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ultralytics==8.0.20) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ultralytics==8.0.20) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ultralytics==8.0.20) (0.2.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->ultralytics==8.0.20) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics==8.0.20) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.20) (3.2.2)\n",
            "Installing collected packages: sentry-sdk, jedi, thop, ultralytics\n",
            "Successfully installed jedi-0.19.1 sentry-sdk-1.38.0 thop-0.1.1.post2209072238 ultralytics-8.0.20\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bezuAaHBsc8D",
        "outputId": "3efae870-b964-45a2-8350-5719df9860b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 27.0/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu4-tU-svaeq"
      },
      "outputs": [],
      "source": [
        "!apt install unzip\n",
        "!unzip -u '/content/drive/MyDrive/Worker safety detection.zip' -d '/content/drive/MyDrive/Worker safety Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKqwReFpseVk",
        "outputId": "f96e7037-cbdf-4c7d-d31f-4f14e068cf10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/drive/MyDrive/Worker_safety_Data/safety.yaml, epochs=30, patience=10, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train2\n",
            "2023-12-10 05:48:41.994443: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 05:48:41.994493: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 05:48:41.994528: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 05:48:42.974050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.Detect                [10, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/labels.cache... 2605 images, 6 backgrounds, 0 corrupt: 100% 2605/2605 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/valid/labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100% 114/114 [00:00<?, ?it/s]\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      9.62G      1.367       3.05      1.448        477        640: 100% 163/163 [02:35<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:24<00:00,  6.04s/it]\n",
            "                   all        114        697      0.362      0.239      0.213     0.0965\n",
            "               Hardhat        114         79      0.502      0.509       0.44      0.233\n",
            "                  Mask        114         21     0.0688     0.0476     0.0492      0.017\n",
            "            NO-Hardhat        114         69      0.158      0.101     0.0764     0.0273\n",
            "               NO-Mask        114         74          0          0     0.0717     0.0244\n",
            "        NO-Safety Vest        114        106      0.266     0.0943      0.122     0.0484\n",
            "                Person        114        166       0.52      0.452      0.424      0.175\n",
            "           Safety Cone        114         44      0.408       0.25      0.214        0.1\n",
            "           Safety Vest        114         41      0.303      0.415       0.33       0.13\n",
            "             machinery        114         55      0.396      0.525      0.391      0.204\n",
            "               vehicle        114         42          1          0     0.0168    0.00548\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30        11G      1.293      2.017      1.401        296        640: 100% 163/163 [02:02<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.76it/s]\n",
            "                   all        114        697      0.506      0.312      0.344      0.151\n",
            "               Hardhat        114         79      0.832      0.544      0.626      0.329\n",
            "                  Mask        114         21      0.499      0.524      0.523      0.269\n",
            "            NO-Hardhat        114         69      0.575      0.157      0.217     0.0708\n",
            "               NO-Mask        114         74      0.675      0.197      0.273     0.0919\n",
            "        NO-Safety Vest        114        106      0.484      0.124      0.238     0.0812\n",
            "                Person        114        166      0.609      0.347      0.441       0.18\n",
            "           Safety Cone        114         44      0.435      0.409      0.372       0.16\n",
            "           Safety Vest        114         41      0.521      0.463      0.466       0.18\n",
            "             machinery        114         55      0.238      0.236       0.18     0.0859\n",
            "               vehicle        114         42      0.194      0.119      0.108     0.0599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30        11G      1.278      1.835      1.403        325        640: 100% 163/163 [02:01<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.80it/s]\n",
            "                   all        114        697      0.533       0.41      0.414      0.183\n",
            "               Hardhat        114         79      0.616      0.696      0.682      0.376\n",
            "                  Mask        114         21      0.898      0.421      0.541      0.266\n",
            "            NO-Hardhat        114         69       0.53      0.261      0.286      0.108\n",
            "               NO-Mask        114         74      0.536       0.23      0.268        0.1\n",
            "        NO-Safety Vest        114        106      0.286      0.208      0.206     0.0803\n",
            "                Person        114        166      0.702      0.506      0.514      0.228\n",
            "           Safety Cone        114         44      0.586      0.547      0.486      0.211\n",
            "           Safety Vest        114         41      0.507      0.585      0.548      0.221\n",
            "             machinery        114         55      0.556      0.364      0.408       0.15\n",
            "               vehicle        114         42      0.111      0.286      0.206     0.0941\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30        11G      1.294      1.782      1.413        325        640: 100% 163/163 [02:02<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.80it/s]\n",
            "                   all        114        697      0.622      0.389      0.438      0.209\n",
            "               Hardhat        114         79      0.691      0.539      0.606      0.338\n",
            "                  Mask        114         21      0.618      0.667      0.618      0.338\n",
            "            NO-Hardhat        114         69      0.613      0.276       0.34      0.133\n",
            "               NO-Mask        114         74       0.45      0.176      0.291       0.12\n",
            "        NO-Safety Vest        114        106      0.639      0.251      0.336      0.137\n",
            "                Person        114        166      0.559      0.488      0.474      0.215\n",
            "           Safety Cone        114         44       0.57      0.705      0.595      0.247\n",
            "           Safety Vest        114         41      0.658      0.341      0.497      0.246\n",
            "             machinery        114         55      0.777      0.253      0.391      0.206\n",
            "               vehicle        114         42      0.642       0.19      0.229      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30        11G      1.265      1.686      1.389        246        640: 100% 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 4/4 [00:02<00:00,  1.92it/s]\n",
            "                   all        114        697      0.595      0.384      0.406      0.179\n",
            "               Hardhat        114         79      0.816      0.618       0.65      0.349\n",
            "                  Mask        114         21      0.804      0.476      0.513      0.177\n",
            "            NO-Hardhat        114         69      0.575      0.177      0.266     0.0944\n",
            "               NO-Mask        114         74      0.538      0.189      0.286      0.122\n",
            "        NO-Safety Vest        114        106      0.552       0.33      0.355      0.155\n",
            "                Person        114        166      0.559      0.465      0.494      0.202\n",
            "           Safety Cone        114         44      0.798      0.449      0.476      0.197\n",
            "           Safety Vest        114         41      0.594      0.439      0.462      0.227\n",
            "             machinery        114         55      0.265      0.527      0.323      0.155\n",
            "               vehicle        114         42      0.449      0.175      0.233      0.109\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 249, in entrypoint\n",
            "    getattr(model, mode)(verbose=True, **overrides)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/model.py\", line 207, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py\", line 183, in train\n",
            "    self._do_train(int(os.getenv(\"RANK\", -1)), world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py\", line 343, in _do_train\n",
            "    self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/trainer.py\", line 500, in save_metrics\n",
            "    with open(self.csv, 'a') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/detect/train2/results.csv'\n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train epochs=30 data='/content/drive/MyDrive/Worker_safety_Data/safety.yaml' model=yolov8n.pt imgsz=640 patience=10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model=YOLO('/content/runs/detect/train2/weights/best.pt')\n",
        "metrics = model.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIiVuOvltNwt",
        "outputId": "7e0203f1-2e95-4392-e4fa-7618de65fd80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/valid/labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:07<00:00,  1.07it/s]\n",
            "                   all        114        697       0.84      0.668       0.74      0.434\n",
            "               Hardhat        114         79      0.935      0.747      0.818      0.537\n",
            "                  Mask        114         21      0.922       0.81      0.882      0.604\n",
            "            NO-Hardhat        114         69        0.8      0.565      0.637      0.318\n",
            "               NO-Mask        114         74      0.854      0.473      0.556      0.264\n",
            "        NO-Safety Vest        114        106      0.788      0.562      0.663      0.371\n",
            "                Person        114        166      0.785      0.726      0.782      0.451\n",
            "           Safety Cone        114         44       0.83      0.841      0.846      0.445\n",
            "           Safety Vest        114         41      0.858      0.732      0.827      0.495\n",
            "             machinery        114         55      0.774       0.81      0.857      0.553\n",
            "               vehicle        114         42      0.852      0.411      0.529      0.299\n",
            "Speed: 0.3ms pre-process, 8.8ms inference, 0.0ms loss, 9.0ms post-process per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "8UBL79S4UphP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model=YOLO('/content/drive/MyDrive/runs/detect/train2/weights/last.pt')  # load a partially trained model\n",
        "\n",
        "# Resume training\n",
        "results = model.train(resume=True)"
      ],
      "metadata": {
        "id": "naXvaVGTvCnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2883fca-4ba0-4289-e194-a2a579e2454c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/runs/detect/train2/weights/last.pt, data=/content/drive/MyDrive/Worker_safety_Data/safety.yaml, epochs=30, patience=10, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.Detect                [10, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/labels.cache... 2605 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2605/2605 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/images/004720_jpg.rf.afc486560a4004c7cfd67910af31a29c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/train/images/construction-813-_jpg.rf.b085952261fd98f2e76b8065de149b5f.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/valid/labels.cache... 114 images, 10 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 114/114 [00:00<?, ?it/s]\n",
            "Resuming training from /content/drive/MyDrive/runs/detect/train2/weights/last.pt from epoch 4 to 30 total epochs\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      9.62G      1.279      1.703      1.393        477        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:08<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.08it/s]\n",
            "                   all        114        697      0.636      0.385      0.438      0.197\n",
            "               Hardhat        114         79      0.592      0.671       0.67      0.359\n",
            "                  Mask        114         21      0.937      0.524      0.731      0.346\n",
            "            NO-Hardhat        114         69      0.517      0.246       0.28      0.103\n",
            "               NO-Mask        114         74      0.457      0.307      0.267     0.0844\n",
            "        NO-Safety Vest        114        106      0.552      0.179      0.246     0.0935\n",
            "                Person        114        166      0.614       0.38      0.433      0.164\n",
            "           Safety Cone        114         44      0.757      0.364      0.442      0.173\n",
            "           Safety Vest        114         41      0.617      0.488      0.526      0.273\n",
            "             machinery        114         55      0.635      0.436      0.446        0.2\n",
            "               vehicle        114         42      0.683      0.257      0.334      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30        11G      1.259      1.631      1.381        296        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:02<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.76it/s]\n",
            "                   all        114        697      0.598       0.39      0.422      0.195\n",
            "               Hardhat        114         79      0.837      0.544      0.638      0.356\n",
            "                  Mask        114         21      0.773      0.651      0.695      0.355\n",
            "            NO-Hardhat        114         69      0.571       0.29      0.341      0.101\n",
            "               NO-Mask        114         74      0.505      0.297       0.31      0.118\n",
            "        NO-Safety Vest        114        106      0.611      0.193      0.292      0.118\n",
            "                Person        114        166      0.683      0.337      0.446      0.192\n",
            "           Safety Cone        114         44      0.628      0.537      0.567      0.241\n",
            "           Safety Vest        114         41      0.706      0.463      0.501       0.28\n",
            "             machinery        114         55      0.232      0.345      0.241      0.117\n",
            "               vehicle        114         42      0.439      0.238      0.191     0.0752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30        11G      1.225      1.563      1.359        325        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:02<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]\n",
            "                   all        114        697      0.654      0.503      0.561      0.248\n",
            "               Hardhat        114         79      0.777       0.62      0.672      0.373\n",
            "                  Mask        114         21      0.781      0.571      0.698      0.304\n",
            "            NO-Hardhat        114         69      0.812      0.304      0.482      0.184\n",
            "               NO-Mask        114         74      0.536      0.312      0.346      0.122\n",
            "        NO-Safety Vest        114        106      0.636      0.296      0.415      0.149\n",
            "                Person        114        166      0.731      0.605      0.629      0.269\n",
            "           Safety Cone        114         44      0.743       0.75      0.784      0.361\n",
            "           Safety Vest        114         41      0.483      0.659      0.671      0.283\n",
            "             machinery        114         55      0.612      0.655      0.658      0.278\n",
            "               vehicle        114         42      0.434      0.256      0.253       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30        11G      1.201      1.492      1.343        325        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]\n",
            "                   all        114        697      0.738      0.503      0.562      0.272\n",
            "               Hardhat        114         79      0.788      0.658      0.725      0.429\n",
            "                  Mask        114         21      0.814      0.837      0.813      0.421\n",
            "            NO-Hardhat        114         69      0.777      0.391      0.477      0.193\n",
            "               NO-Mask        114         74      0.685      0.297      0.338       0.12\n",
            "        NO-Safety Vest        114        106      0.545      0.407      0.405      0.178\n",
            "                Person        114        166      0.758      0.596      0.636      0.278\n",
            "           Safety Cone        114         44       0.75      0.591      0.706      0.315\n",
            "           Safety Vest        114         41      0.873      0.561       0.67      0.329\n",
            "             machinery        114         55      0.628      0.473      0.531      0.272\n",
            "               vehicle        114         42      0.758      0.214      0.315      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30        11G      1.205      1.475      1.341        246        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.28it/s]\n",
            "                   all        114        697      0.714      0.504       0.56       0.24\n",
            "               Hardhat        114         79      0.894       0.62       0.71      0.344\n",
            "                  Mask        114         21      0.918      0.714      0.773      0.316\n",
            "            NO-Hardhat        114         69      0.639      0.275      0.362      0.119\n",
            "               NO-Mask        114         74        0.9      0.242      0.434      0.153\n",
            "        NO-Safety Vest        114        106      0.516      0.406      0.406      0.197\n",
            "                Person        114        166      0.728       0.53      0.561      0.223\n",
            "           Safety Cone        114         44      0.773      0.659      0.722      0.312\n",
            "           Safety Vest        114         41      0.769      0.568      0.675      0.295\n",
            "             machinery        114         55      0.669        0.6      0.621      0.294\n",
            "               vehicle        114         42      0.332      0.429      0.333      0.147\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30        11G       1.18      1.411      1.328        404        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:02<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.91it/s]\n",
            "                   all        114        697      0.702      0.505      0.572      0.271\n",
            "               Hardhat        114         79       0.85      0.608        0.7      0.398\n",
            "                  Mask        114         21      0.846      0.762      0.797      0.333\n",
            "            NO-Hardhat        114         69      0.752      0.377      0.484      0.179\n",
            "               NO-Mask        114         74      0.681      0.311      0.413       0.17\n",
            "        NO-Safety Vest        114        106      0.614      0.396      0.449      0.209\n",
            "                Person        114        166      0.723      0.583      0.658      0.299\n",
            "           Safety Cone        114         44      0.837      0.584      0.631      0.294\n",
            "           Safety Vest        114         41      0.724      0.561      0.685      0.367\n",
            "             machinery        114         55      0.588      0.491      0.592      0.295\n",
            "               vehicle        114         42        0.4      0.381      0.309      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      12.7G      1.168      1.352      1.311        356        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]\n",
            "                   all        114        697      0.673      0.579      0.611      0.291\n",
            "               Hardhat        114         79      0.798      0.684      0.736      0.423\n",
            "                  Mask        114         21      0.764       0.77      0.812      0.385\n",
            "            NO-Hardhat        114         69      0.579      0.377      0.417      0.167\n",
            "               NO-Mask        114         74      0.487      0.446      0.431      0.164\n",
            "        NO-Safety Vest        114        106      0.674      0.453      0.497      0.234\n",
            "                Person        114        166      0.679      0.578      0.641       0.28\n",
            "           Safety Cone        114         44      0.837      0.702      0.789       0.36\n",
            "           Safety Vest        114         41      0.834      0.613      0.702      0.358\n",
            "             machinery        114         55      0.678      0.764      0.762      0.384\n",
            "               vehicle        114         42      0.402      0.401      0.328      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      12.7G      1.158      1.347      1.312        268        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.53it/s]\n",
            "                   all        114        697      0.722      0.571      0.621      0.307\n",
            "               Hardhat        114         79      0.875      0.646      0.739      0.435\n",
            "                  Mask        114         21      0.665      0.762      0.764      0.365\n",
            "            NO-Hardhat        114         69      0.661      0.424      0.449      0.163\n",
            "               NO-Mask        114         74      0.809      0.324      0.446      0.161\n",
            "        NO-Safety Vest        114        106      0.614      0.462      0.546      0.273\n",
            "                Person        114        166       0.77      0.606      0.668      0.366\n",
            "           Safety Cone        114         44      0.862      0.708      0.794      0.374\n",
            "           Safety Vest        114         41      0.711      0.683      0.724      0.345\n",
            "             machinery        114         55      0.599      0.782      0.727      0.358\n",
            "               vehicle        114         42      0.649      0.309      0.348      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      12.7G      1.145       1.31      1.297        441        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:04<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.74it/s]\n",
            "                   all        114        697      0.725      0.572      0.624      0.302\n",
            "               Hardhat        114         79      0.912      0.659      0.741      0.439\n",
            "                  Mask        114         21      0.916       0.81      0.832      0.425\n",
            "            NO-Hardhat        114         69      0.538      0.507      0.513      0.201\n",
            "               NO-Mask        114         74      0.723      0.388      0.457      0.193\n",
            "        NO-Safety Vest        114        106       0.64       0.42      0.487      0.225\n",
            "                Person        114        166      0.724      0.639      0.697      0.334\n",
            "           Safety Cone        114         44      0.805      0.749      0.808      0.362\n",
            "           Safety Vest        114         41      0.857      0.512       0.68      0.372\n",
            "             machinery        114         55      0.542      0.727      0.659      0.292\n",
            "               vehicle        114         42      0.595      0.315      0.365      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      12.7G       1.13      1.277      1.292        228        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]\n",
            "                   all        114        697      0.743      0.606      0.652      0.297\n",
            "               Hardhat        114         79      0.893      0.684      0.773      0.422\n",
            "                  Mask        114         21      0.852       0.81      0.779      0.345\n",
            "            NO-Hardhat        114         69      0.795      0.507      0.602      0.207\n",
            "               NO-Mask        114         74      0.576      0.446      0.484      0.158\n",
            "        NO-Safety Vest        114        106      0.729      0.462      0.524      0.215\n",
            "                Person        114        166      0.664      0.651      0.676      0.322\n",
            "           Safety Cone        114         44      0.907      0.663      0.785       0.38\n",
            "           Safety Vest        114         41      0.712      0.659      0.724      0.354\n",
            "             machinery        114         55      0.711      0.818      0.798      0.367\n",
            "               vehicle        114         42      0.589      0.357      0.374        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      12.7G       1.11      1.244      1.278        296        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]\n",
            "                   all        114        697      0.746      0.573      0.641       0.31\n",
            "               Hardhat        114         79      0.905      0.608      0.762       0.44\n",
            "                  Mask        114         21      0.933       0.81      0.817      0.394\n",
            "            NO-Hardhat        114         69      0.683      0.406      0.487      0.193\n",
            "               NO-Mask        114         74      0.707      0.405      0.515      0.212\n",
            "        NO-Safety Vest        114        106      0.715        0.5      0.566      0.257\n",
            "                Person        114        166      0.723      0.663      0.697      0.329\n",
            "           Safety Cone        114         44      0.791      0.602      0.724      0.309\n",
            "           Safety Vest        114         41      0.736       0.68      0.672      0.348\n",
            "             machinery        114         55      0.687      0.691      0.748      0.383\n",
            "               vehicle        114         42      0.584      0.368      0.428       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      12.7G      1.089      1.213      1.266        265        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.36it/s]\n",
            "                   all        114        697      0.839      0.588      0.665      0.358\n",
            "               Hardhat        114         79      0.981      0.665       0.77      0.487\n",
            "                  Mask        114         21      0.801      0.766      0.809      0.479\n",
            "            NO-Hardhat        114         69      0.785      0.522      0.542      0.223\n",
            "               NO-Mask        114         74      0.857      0.392      0.513      0.209\n",
            "        NO-Safety Vest        114        106      0.858      0.434      0.553      0.283\n",
            "                Person        114        166      0.826      0.629      0.694       0.37\n",
            "           Safety Cone        114         44      0.826      0.795      0.814      0.404\n",
            "           Safety Vest        114         41      0.928      0.629      0.731      0.449\n",
            "             machinery        114         55      0.808      0.689      0.806       0.44\n",
            "               vehicle        114         42      0.721      0.357      0.417      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30      12.7G      1.087      1.196      1.262        249        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]\n",
            "                   all        114        697      0.786      0.569      0.647      0.322\n",
            "               Hardhat        114         79      0.926      0.709      0.775      0.448\n",
            "                  Mask        114         21      0.886       0.74      0.779      0.392\n",
            "            NO-Hardhat        114         69      0.703      0.362      0.479      0.184\n",
            "               NO-Mask        114         74      0.755      0.405      0.518      0.201\n",
            "        NO-Safety Vest        114        106      0.731      0.472       0.55      0.261\n",
            "                Person        114        166      0.777       0.63      0.709      0.359\n",
            "           Safety Cone        114         44      0.786       0.75      0.788      0.382\n",
            "           Safety Vest        114         41      0.941       0.61      0.735      0.397\n",
            "             machinery        114         55      0.794        0.7      0.797      0.413\n",
            "               vehicle        114         42      0.556       0.31      0.341      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      12.7G      1.076      1.172      1.259        275        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.94it/s]\n",
            "                   all        114        697      0.758      0.581      0.651      0.352\n",
            "               Hardhat        114         79      0.899      0.671      0.768      0.495\n",
            "                  Mask        114         21      0.911       0.81      0.836      0.478\n",
            "            NO-Hardhat        114         69      0.769       0.42      0.501      0.215\n",
            "               NO-Mask        114         74      0.741      0.365      0.479      0.214\n",
            "        NO-Safety Vest        114        106      0.694      0.471       0.56       0.27\n",
            "                Person        114        166      0.811      0.633      0.723      0.413\n",
            "           Safety Cone        114         44      0.694      0.682      0.738      0.349\n",
            "           Safety Vest        114         41      0.717      0.659      0.726      0.415\n",
            "             machinery        114         55      0.779      0.673      0.779      0.433\n",
            "               vehicle        114         42      0.562      0.429      0.402       0.24\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      12.7G      1.061      1.143      1.245        299        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.43it/s]\n",
            "                   all        114        697      0.794      0.609      0.677       0.35\n",
            "               Hardhat        114         79      0.913      0.696      0.797      0.495\n",
            "                  Mask        114         21      0.994       0.81      0.874      0.461\n",
            "            NO-Hardhat        114         69       0.81      0.406      0.509      0.213\n",
            "               NO-Mask        114         74       0.64      0.432      0.474      0.205\n",
            "        NO-Safety Vest        114        106      0.808      0.462      0.582       0.27\n",
            "                Person        114        166      0.782      0.687      0.762      0.414\n",
            "           Safety Cone        114         44      0.833       0.75      0.814      0.351\n",
            "           Safety Vest        114         41      0.827      0.699      0.763      0.393\n",
            "             machinery        114         55      0.697      0.745      0.772      0.464\n",
            "               vehicle        114         42      0.634      0.405      0.423      0.238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      12.7G      1.055      1.125      1.241        256        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [02:03<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.85it/s]\n",
            "                   all        114        697      0.808      0.622      0.687       0.33\n",
            "               Hardhat        114         79      0.903      0.684       0.78      0.463\n",
            "                  Mask        114         21      0.852      0.762      0.758      0.307\n",
            "            NO-Hardhat        114         69       0.82      0.493       0.55      0.221\n",
            "               NO-Mask        114         74      0.759      0.383      0.511      0.229\n",
            "        NO-Safety Vest        114        106      0.852      0.462      0.615      0.276\n",
            "                Person        114        166      0.768      0.614      0.703      0.336\n",
            "           Safety Cone        114         44      0.888      0.818      0.876      0.365\n",
            "           Safety Vest        114         41      0.846      0.672      0.747      0.413\n",
            "             machinery        114         55      0.769      0.855       0.85      0.444\n",
            "               vehicle        114         42      0.624      0.473      0.476      0.246\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      12.7G      1.091      1.093      1.268        131        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:09<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.62it/s]\n",
            "                   all        114        697      0.783      0.618      0.667      0.335\n",
            "               Hardhat        114         79      0.914      0.709      0.761      0.444\n",
            "                  Mask        114         21      0.857       0.81      0.839      0.385\n",
            "            NO-Hardhat        114         69      0.735      0.449      0.559      0.231\n",
            "               NO-Mask        114         74      0.749      0.365       0.46      0.201\n",
            "        NO-Safety Vest        114        106      0.711      0.472      0.535      0.272\n",
            "                Person        114        166       0.75      0.668      0.684       0.36\n",
            "           Safety Cone        114         44      0.879       0.75      0.799      0.388\n",
            "           Safety Vest        114         41      0.753      0.742      0.729      0.354\n",
            "             machinery        114         55      0.806      0.832      0.863      0.491\n",
            "               vehicle        114         42      0.677      0.381      0.438      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30      12.7G      1.071      1.046      1.259        189        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:06<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.90it/s]\n",
            "                   all        114        697      0.847      0.614      0.695      0.363\n",
            "               Hardhat        114         79      0.893      0.709      0.809      0.466\n",
            "                  Mask        114         21        0.9      0.762      0.828       0.48\n",
            "            NO-Hardhat        114         69      0.865      0.507      0.575      0.245\n",
            "               NO-Mask        114         74      0.777      0.424      0.515      0.224\n",
            "        NO-Safety Vest        114        106        0.8      0.528      0.629      0.287\n",
            "                Person        114        166      0.882      0.633      0.737      0.393\n",
            "           Safety Cone        114         44      0.947      0.815       0.86      0.439\n",
            "           Safety Vest        114         41        0.9       0.66      0.784      0.424\n",
            "             machinery        114         55      0.742      0.745      0.792      0.427\n",
            "               vehicle        114         42      0.765      0.357      0.418      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      12.7G      1.056       1.01      1.245        143        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.77it/s]\n",
            "                   all        114        697      0.789      0.639      0.697      0.379\n",
            "               Hardhat        114         79      0.857      0.734      0.806        0.5\n",
            "                  Mask        114         21      0.806      0.762      0.843      0.499\n",
            "            NO-Hardhat        114         69      0.901      0.529      0.582      0.258\n",
            "               NO-Mask        114         74      0.783      0.432      0.525      0.243\n",
            "        NO-Safety Vest        114        106      0.812      0.531      0.646      0.308\n",
            "                Person        114        166      0.802      0.651      0.748      0.433\n",
            "           Safety Cone        114         44       0.82      0.725      0.792      0.386\n",
            "           Safety Vest        114         41       0.74      0.707      0.757      0.438\n",
            "             machinery        114         55      0.623      0.891      0.837      0.492\n",
            "               vehicle        114         42      0.748      0.424      0.434      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      12.7G      1.048     0.9952      1.237        162        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:07<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.86it/s]\n",
            "                   all        114        697      0.832      0.636      0.715      0.388\n",
            "               Hardhat        114         79      0.887      0.694      0.802      0.492\n",
            "                  Mask        114         21      0.943      0.794      0.877      0.498\n",
            "            NO-Hardhat        114         69      0.772      0.522      0.572      0.233\n",
            "               NO-Mask        114         74      0.828      0.378      0.513      0.225\n",
            "        NO-Safety Vest        114        106      0.659      0.557      0.594      0.282\n",
            "                Person        114        166      0.807      0.669      0.759      0.446\n",
            "           Safety Cone        114         44       0.91      0.795      0.844      0.418\n",
            "           Safety Vest        114         41       0.91      0.737      0.818      0.442\n",
            "             machinery        114         55      0.855      0.859      0.908      0.578\n",
            "               vehicle        114         42      0.748      0.357      0.461      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      12.7G      1.022     0.9544      1.219        159        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.92it/s]\n",
            "                   all        114        697      0.823      0.641      0.698      0.374\n",
            "               Hardhat        114         79        0.9      0.681      0.783      0.486\n",
            "                  Mask        114         21      0.992       0.81      0.854      0.474\n",
            "            NO-Hardhat        114         69      0.791      0.507      0.549      0.234\n",
            "               NO-Mask        114         74      0.833      0.473      0.541      0.256\n",
            "        NO-Safety Vest        114        106      0.747      0.547      0.635      0.315\n",
            "                Person        114        166      0.837      0.645      0.738      0.393\n",
            "           Safety Cone        114         44      0.783      0.795      0.818      0.417\n",
            "           Safety Vest        114         41      0.876      0.707      0.762      0.422\n",
            "             machinery        114         55      0.862      0.794      0.867      0.521\n",
            "               vehicle        114         42      0.608      0.452      0.436      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30      12.7G      1.014     0.9349      1.216        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:07<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.66it/s]\n",
            "                   all        114        697      0.828      0.652      0.711      0.397\n",
            "               Hardhat        114         79      0.935      0.696      0.794      0.517\n",
            "                  Mask        114         21      0.955       0.81      0.866      0.526\n",
            "            NO-Hardhat        114         69      0.716      0.478       0.54      0.243\n",
            "               NO-Mask        114         74       0.83      0.473       0.55      0.261\n",
            "        NO-Safety Vest        114        106      0.776      0.547      0.637      0.348\n",
            "                Person        114        166      0.835      0.675       0.74       0.41\n",
            "           Safety Cone        114         44      0.919      0.841      0.868      0.439\n",
            "           Safety Vest        114         41      0.879      0.707      0.802      0.449\n",
            "             machinery        114         55      0.775      0.836      0.878      0.526\n",
            "               vehicle        114         42      0.657      0.456      0.432      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      12.7G     0.9991     0.9143      1.207        185        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.87it/s]\n",
            "                   all        114        697      0.775      0.699      0.728      0.422\n",
            "               Hardhat        114         79      0.823      0.785      0.795      0.512\n",
            "                  Mask        114         21      0.942      0.857      0.901      0.594\n",
            "            NO-Hardhat        114         69      0.841      0.551      0.601       0.32\n",
            "               NO-Mask        114         74      0.759      0.468      0.555      0.266\n",
            "        NO-Safety Vest        114        106      0.746      0.604      0.659      0.379\n",
            "                Person        114        166      0.692      0.718      0.743      0.434\n",
            "           Safety Cone        114         44      0.772      0.841      0.835      0.407\n",
            "           Safety Vest        114         41      0.798      0.773      0.827      0.451\n",
            "             machinery        114         55      0.803      0.891      0.868      0.567\n",
            "               vehicle        114         42      0.571        0.5       0.49      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      12.7G     0.9884     0.8975        1.2        175        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.33it/s]\n",
            "                   all        114        697      0.842      0.658       0.74      0.414\n",
            "               Hardhat        114         79      0.955      0.671      0.805      0.519\n",
            "                  Mask        114         21      0.943      0.792      0.868      0.547\n",
            "            NO-Hardhat        114         69      0.839      0.531      0.611      0.295\n",
            "               NO-Mask        114         74       0.81        0.5       0.58      0.244\n",
            "        NO-Safety Vest        114        106      0.812      0.585      0.679      0.357\n",
            "                Person        114        166      0.781      0.693      0.766      0.421\n",
            "           Safety Cone        114         44      0.866      0.818      0.849      0.448\n",
            "           Safety Vest        114         41      0.907      0.717      0.849      0.494\n",
            "             machinery        114         55      0.788      0.873      0.865      0.542\n",
            "               vehicle        114         42      0.722      0.405       0.53      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      12.7G     0.9747     0.8789      1.186        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.89it/s]\n",
            "                   all        114        697       0.84      0.666      0.739      0.432\n",
            "               Hardhat        114         79      0.936      0.741      0.818       0.54\n",
            "                  Mask        114         21      0.923       0.81      0.882      0.607\n",
            "            NO-Hardhat        114         69      0.803      0.565      0.626      0.316\n",
            "               NO-Mask        114         74      0.858      0.473      0.556      0.256\n",
            "        NO-Safety Vest        114        106      0.786      0.554      0.664      0.368\n",
            "                Person        114        166      0.779      0.723      0.781      0.449\n",
            "           Safety Cone        114         44      0.851      0.841       0.85      0.446\n",
            "           Safety Vest        114         41      0.861      0.732      0.827      0.494\n",
            "             machinery        114         55      0.804      0.818      0.864      0.551\n",
            "               vehicle        114         42      0.801      0.405      0.522      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      12.7G     0.9673     0.8621      1.183        128        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163/163 [01:05<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.33s/it]\n",
            "                   all        114        697      0.818      0.698      0.748      0.427\n",
            "               Hardhat        114         79      0.894      0.745      0.807      0.527\n",
            "                  Mask        114         21      0.916      0.857        0.9      0.548\n",
            "            NO-Hardhat        114         69        0.8      0.578      0.631      0.299\n",
            "               NO-Mask        114         74      0.858      0.571      0.603      0.281\n",
            "        NO-Safety Vest        114        106      0.854      0.608      0.695      0.381\n",
            "                Person        114        166      0.761      0.723      0.789       0.45\n",
            "           Safety Cone        114         44      0.806      0.818      0.834      0.433\n",
            "           Safety Vest        114         41      0.846       0.78      0.838      0.501\n",
            "             machinery        114         55      0.814      0.855      0.897      0.582\n",
            "               vehicle        114         42      0.631      0.448      0.485      0.272\n",
            "\n",
            "26 epochs completed in 0.761 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]\n",
            "                   all        114        697      0.839      0.665      0.738      0.432\n",
            "               Hardhat        114         79      0.936      0.747      0.818      0.538\n",
            "                  Mask        114         21      0.924       0.81      0.883      0.607\n",
            "            NO-Hardhat        114         69      0.804      0.565      0.626      0.316\n",
            "               NO-Mask        114         74      0.858      0.473      0.555      0.258\n",
            "        NO-Safety Vest        114        106      0.786      0.555      0.664      0.368\n",
            "                Person        114        166      0.778      0.723       0.78      0.449\n",
            "           Safety Cone        114         44      0.851      0.841      0.849      0.441\n",
            "           Safety Vest        114         41      0.861      0.732      0.826      0.493\n",
            "             machinery        114         55      0.786        0.8      0.857      0.552\n",
            "               vehicle        114         42      0.801      0.405      0.523      0.296\n",
            "Speed: 0.4ms pre-process, 5.6ms inference, 0.0ms loss, 5.5ms post-process per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r WSD3.zip /content/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvzRVptuf_IJ",
        "outputId": "dd9de3ee-c4d5-4591-91b9-b316fe5c4159"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/detect/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/val_batch1_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train2/val_batch2_pred.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train2/results.png (deflated 9%)\n",
            "  adding: content/runs/detect/train2/args.yaml (deflated 52%)\n",
            "  adding: content/runs/detect/train2/train_batch3260.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train2/P_curve.png (deflated 5%)\n",
            "  adding: content/runs/detect/train2/val_batch2_labels.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train2/val_batch0_pred.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/train2/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train2/weights/best.pt (deflated 9%)\n",
            "  adding: content/runs/detect/train2/weights/last.pt (deflated 9%)\n",
            "  adding: content/runs/detect/train2/confusion_matrix.png (deflated 17%)\n",
            "  adding: content/runs/detect/train2/train_batch3261.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/train2/train_batch3262.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/train2/val_batch1_pred.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train2/results.csv (deflated 84%)\n",
            "  adding: content/runs/detect/train2/R_curve.png (deflated 5%)\n",
            "  adding: content/runs/detect/train2/F1_curve.png (deflated 4%)\n",
            "  adding: content/runs/detect/train2/val_batch0_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/train2/PR_curve.png (deflated 6%)\n",
            "  adding: content/runs/detect/train2/events.out.tfevents.1702188224.06a046454fea.967.0 (deflated 72%)\n",
            "  adding: content/runs/detect/train/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/val/ (stored 0%)\n",
            "  adding: content/runs/detect/val/val_batch1_labels.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/val/val_batch2_pred.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/val/P_curve.png (deflated 5%)\n",
            "  adding: content/runs/detect/val/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/val/val_batch0_pred.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/val/confusion_matrix.png (deflated 17%)\n",
            "  adding: content/runs/detect/val/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/val/R_curve.png (deflated 5%)\n",
            "  adding: content/runs/detect/val/F1_curve.png (deflated 4%)\n",
            "  adding: content/runs/detect/val/val_batch0_labels.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/val/PR_curve.png (deflated 7%)\n",
            "  adding: content/runs/detect/predict/ (stored 0%)\n",
            "  adding: content/runs/detect/predict/-4405-_png_jpg.rf.82b5c10b2acd1cfaa24259ada8e599fe.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-462_jpg.rf.df73aa5089a04b8fbf3adf9d614a6740.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/2009_000496_jpg.rf.9a2d210fe0f5ea4b572aeb07e41ecbae.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/construction-192-_jpg.rf.56dd5c4c1396c6ad01be4fbec3bca46f.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/predict/004063_jpg.rf.1b7cdc4035bcb24ef69b8798b444053e.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/class2_131_jpg.rf.ad8314a9273471f1280ce8789ea75376.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/autox_mp4-44_jpg.rf.5048603ee6ccedf9ae6e3f787b7f82ff.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-472_jpg.rf.e9425ff40c0df2beeef70abbc2324956.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/Movie-on-10-31-22-at-10_08-AM_mov-24_jpg.rf.c50014f3510a484e5bd565460fd0fd5c.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/Movie-on-10-31-22-at-10_08-AM_mov-20_jpg.rf.aea4278b41550cdb75df5891a26052e7.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-800-_jpg.rf.a01fcddd0db9cc89c0cacf4af88c468d.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/autox3_mp4-65_jpg.rf.d933ce48947fa9bdb55dc702a0879ac9.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/006672_jpg.rf.87d5978c486feb53177408cf00a0d87f.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/3e7e40981ddd4cdb055c7ffe4c2af5d8_jpg.rf.bac50dc18195e9aeb6f3a21782a3efcb.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/RPReplay_Final1667001201_MP4-100_jpg.rf.9a1b50c4301c53b3ae534c6353337df9.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/youtube-114_jpg.rf.5e02b6574ace1f4b3689befbc5051cd0.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/class2_145_jpg.rf.b8ed5a5357ee41f8fb1aa9b01a400d51.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/IMG_5846_jpg.rf.0b9984069116e2acd928568eb7a8e214.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/IMG_3100_mp4-9_jpg.rf.413ccf5fe4a7ee67f71e07c2c43b6756.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/ka_01181_png_jpg.rf.154ee4ef254eabd62e316be50470c578.jpg (deflated 9%)\n",
            "  adding: content/runs/detect/predict/youtube-192_jpg.rf.93bea040de8cd55f34ffb12f6ffe30b1.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/ppe_1073_jpg.rf.72ea8a293a4f3e1135219e33701b1099.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-237_jpg.rf.d07a927721fe259757237c3706ea22e5.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-639-_jpg.rf.7db2168ad99f643f7e3070733387e3bb.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/ppe_0018_jpg.rf.be66fabcc8627f60d963454b5a227095.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/youtube-471_jpg.rf.4296b7bd9a5a07753077beddbcd651bf.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/2008_008320_jpg.rf.bd34011d46f82f9410d95f00e560b8ea.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-108_jpg.rf.9dc7ed5f816f07d520f3dbfaad08d40f.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/autox3_mp4-277_jpg.rf.a5ed8fd043fe7e1d8682768880b6d4db.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-198_jpg.rf.e89faeb9765c6bd6cece5434d140f4af.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/IMG_0871_MOV-12_jpg.rf.36858a9d51613f9a39b7855b54dfa098.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/youtube-126_jpg.rf.786824e90daf3276130ca73ca610a8da.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-840_jpg.rf.974a83a7c5aee7c16e83435b043c6d96.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/thumbnail-ba5c72edb320b49a69e86b05775c49b2-scaled-1_jpeg_jpg.rf.3bb460e284098219861b894fb0db13d5.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/image_55_jpg.rf.27ae4341a9b9647d73a8929ff7a22369.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-53_jpg.rf.e96f8f81389f4e63a79663095680a617.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/youtube-671_jpg.rf.7b08643d6754cabe6caf2b49a963de47.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/2009_000059_jpg.rf.50e8398a37eb33f33fd9f662feeea083.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-263_jpg.rf.374e343e12ead395440dbd81417e1be9.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/IMG_0871_mp4-23_jpg.rf.03f872b1ed87ad7fadc85e09475ad37a.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/2008_008519_jpg.rf.1798c8eed7de04399a0e7e297b4b4c9e.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-1159-_jpg.rf.9f3172102a34edb157b556a73931c831.jpg (deflated 20%)\n",
            "  adding: content/runs/detect/predict/006463_jpg.rf.02f19082420ecc5537b9d59abbe6050c.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/youtube-213_jpg.rf.da70b1d8cefd3cc9d56e43bb88dfb67d.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-152_jpg.rf.9147878e3ddda845e58f7d9c041f1338.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-388_jpg.rf.18caa1da4f818a65f73e48463cb2270e.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/IMG_0871_mp4-11_jpg.rf.432092b53ebeb84f4b9b27b40343c9aa.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/777_jpg.rf.92dc6945342410ced7ac93f3dfbff0c5.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-651-_jpg.rf.8fa283ce7693dbdf29eb98384f24cb85.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/librairie_51_jpg.rf.56b0500ae2ad3820b4286133b627e59c.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/construction-2-_mp4-162_jpg.rf.efad5f15524c736fe03b9c9936adc481.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-631_jpg.rf.7c6ecf859c1b0a659f8ea057ad27aebd.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/construction-2-_mp4-84_jpg.rf.e8d6bb0acc5c6e82c1a2d260ddf3135e.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/maksssksksss17_png_jpg.rf.f685b497756b1facbf3d4c2d2d22c0d2.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/youtube-510_jpg.rf.62f82e36d134d53587edb48f291986f4.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/construction-675-_jpg.rf.bb4a05441be707256175e04929da3478.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/youtube-738_jpg.rf.6f300b76e12b325f7c373c95ef319005.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/predict/003357_jpg.rf.9867f91e88089bb68dc95947d5116d14.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/002551_jpg.rf.ce4b9f934161faa72c80dc6898d37b2d.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-186_jpg.rf.1f1d93447d4be3233c22c4ce9f6e0601.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/bookstore_44_08_flickr_jpg.rf.244b6f308c529933af798c4063e58601.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/IMG_3103_mp4-9_jpg.rf.b31bd2d816465a27aa1eb072f90bb5aa.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-2-_mp4-13_jpg.rf.cef0975976346515d438e0c2ce6c59db.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/youtube-596_jpg.rf.11a8a4ac01d8aadb80eeb0406dfa579a.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/004763_jpg.rf.46484e6ca73caeaa9de45822cf1085a9.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/class1_150_jpg.rf.5995dce34d38deb9eb0b6e36cae78f17.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/image_53_jpg.rf.3446e366b5d4d905a32e1aedc8fe87de.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/IMG_3100_mp4-12_jpg.rf.58849ca6a931c2cfe1b17fb4206d9d82.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/000005_jpg.rf.96e9379ccae638140c4a90fc4b700a2b.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/youtube-496_jpg.rf.def4e9964e9a354d0a02f4ac14334a73.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/youtube-253_jpg.rf.5ad0a2d701e20141940508b809584856.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/youtube-34_jpg.rf.03eacc444bae3c5caa3fef5c736c3e40.jpg (deflated 7%)\n",
            "  adding: content/runs/detect/predict/Bookstore_More_Merchandise_jpg.rf.7ab5add3e28ced74f9b316e794cc04d2.jpg (deflated 5%)\n",
            "  adding: content/runs/detect/predict/youtube-263_jpg.rf.bb17b89dd2ec9a090ce53b728f48865e.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/NX_img_177_jpg.rf.c03709e5fadfe2109411f05a9e9bc25f.jpg (deflated 3%)\n",
            "  adding: content/runs/detect/predict/Inside-merge_mov-58_jpg.rf.50147e19cb655e74c2df0047113e82b2.jpg (deflated 6%)\n",
            "  adding: content/runs/detect/predict/0_jpg.rf.2ff49f74309118f169e07aa12564df87.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/autox3_mp4-187_jpg.rf.8340e2bd65afade3fb0d3194eadc5796.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-597-_jpg.rf.e18e918aae0aeecfdf8348513636d344.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-275-_jpg.rf.e1c57987f9dc262aad1d7c67b694fd87.jpg (deflated 4%)\n",
            "  adding: content/runs/detect/predict/construction-843-_jpg.rf.c0ca85a10f6ad3c1375b37e52a51eeed.jpg (deflated 8%)\n",
            "  adding: content/runs/detect/predict/Image36_jpg.rf.8704f3450f736cdd01a61dcee588f2c2.jpg (deflated 2%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/WSD3.zip /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "9mYA929LfygP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('/content/runs/detect/train2/weights/last.pt')\n",
        "\n",
        "# Define path to the image file\n",
        "source = '/content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/test/images/'\n",
        "\n",
        "# Run inference on the source\n",
        "results = model(source)  # list of Results objects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjD4jO5Mis1w",
        "outputId": "96185f67-5d73-4217-b0e7-a9cad4d51088"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('/content/runs/detect/train2/weights/best.pt')\n",
        "\n",
        "# Run inference on some images with arguments\n",
        "model.predict('/content/drive/MyDrive/Worker_safety_Data/Worker_safety_detection/test/images/', save=True, imgsz=320, conf=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y8jE7UPjt1E",
        "outputId": "3e03ce5e-f467-4059-fb0a-c51e1e0e55a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[4.30000e+01, 1.38000e+02, 1.71000e+02, 2.68000e+02, 9.17725e-01, 0.00000e+00],\n",
              "         [6.50000e+01, 2.80000e+02, 1.24000e+02, 3.41000e+02, 8.88394e-01, 3.00000e+00],\n",
              "         [0.00000e+00, 1.29000e+02, 1.84000e+02, 6.28000e+02, 6.89409e-01, 5.00000e+00],\n",
              "         [2.22000e+02, 5.38000e+02, 3.94000e+02, 6.40000e+02, 6.02927e-01, 5.00000e+00],\n",
              "         [2.82000e+02, 1.79000e+02, 4.94000e+02, 6.39000e+02, 5.18594e-01, 5.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[174.00000,  16.00000, 388.00000, 575.00000,   0.84411,   5.00000],\n",
              "         [100.00000, 107.00000, 145.00000, 248.00000,   0.78950,   5.00000],\n",
              "         [109.00000, 110.00000, 127.00000, 133.00000,   0.67440,   0.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[0.00000e+00, 6.10000e+01, 4.58000e+02, 6.39000e+02, 9.14725e-01, 5.00000e+00],\n",
              "         [3.13000e+02, 8.30000e+01, 4.36000e+02, 2.37000e+02, 7.73522e-01, 0.00000e+00],\n",
              "         [1.10000e+01, 1.33000e+02, 3.70000e+02, 6.31000e+02, 5.56524e-01, 4.00000e+00],\n",
              "         [3.72000e+02, 4.93000e+02, 4.13000e+02, 5.83000e+02, 5.34582e-01, 6.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([10, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.91000e+02, 3.32000e+02, 2.49000e+02, 4.37000e+02, 9.00585e-01, 4.00000e+00],\n",
              "         [9.00000e+00, 2.13000e+02, 1.88000e+02, 6.40000e+02, 8.95753e-01, 5.00000e+00],\n",
              "         [1.75000e+02, 2.73000e+02, 2.71000e+02, 6.34000e+02, 8.70785e-01, 5.00000e+00],\n",
              "         [4.47000e+02, 3.92000e+02, 4.98000e+02, 6.15000e+02, 8.13462e-01, 5.00000e+00],\n",
              "         [7.40000e+01, 2.16000e+02, 1.32000e+02, 2.85000e+02, 7.84138e-01, 0.00000e+00],\n",
              "         [6.30000e+01, 2.97000e+02, 1.71000e+02, 4.57000e+02, 7.60297e-01, 4.00000e+00],\n",
              "         [4.99000e+02, 4.19000e+02, 5.46000e+02, 5.99000e+02, 7.32415e-01, 5.00000e+00],\n",
              "         [2.86000e+02, 4.55000e+02, 3.17000e+02, 4.98000e+02, 7.20498e-01, 4.00000e+00],\n",
              "         [2.10000e+02, 2.79000e+02, 2.43000e+02, 3.16000e+02, 6.91591e-01, 0.00000e+00],\n",
              "         [2.83000e+02, 4.29000e+02, 3.27000e+02, 5.96000e+02, 6.20278e-01, 5.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([10, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[3.40000e+01, 5.00000e+01, 2.06000e+02, 2.69000e+02, 9.58191e-01, 0.00000e+00],\n",
              "         [3.45000e+02, 7.50000e+01, 4.41000e+02, 1.83000e+02, 9.20225e-01, 0.00000e+00],\n",
              "         [7.00000e+00, 3.84000e+02, 2.63000e+02, 6.40000e+02, 9.19171e-01, 4.00000e+00],\n",
              "         [3.70000e+02, 2.16000e+02, 4.26000e+02, 2.88000e+02, 8.47328e-01, 3.00000e+00],\n",
              "         [4.18000e+02, 2.84000e+02, 5.03000e+02, 6.33000e+02, 8.02451e-01, 4.00000e+00],\n",
              "         [3.17000e+02, 7.00000e+01, 5.43000e+02, 6.40000e+02, 7.69534e-01, 5.00000e+00],\n",
              "         [1.85000e+02, 1.18000e+02, 3.17000e+02, 6.40000e+02, 7.31614e-01, 5.00000e+00],\n",
              "         [1.95000e+02, 3.60000e+02, 3.02000e+02, 6.39000e+02, 7.21358e-01, 4.00000e+00],\n",
              "         [1.00000e+00, 5.40000e+01, 3.19000e+02, 6.40000e+02, 6.37197e-01, 5.00000e+00],\n",
              "         [3.42000e+02, 2.82000e+02, 4.68000e+02, 6.36000e+02, 5.79219e-01, 4.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([24, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[4.80000e+02, 2.67000e+02, 5.84000e+02, 6.36000e+02, 8.91443e-01, 5.00000e+00],\n",
              "         [1.18000e+02, 2.66000e+02, 2.01000e+02, 5.84000e+02, 8.90646e-01, 5.00000e+00],\n",
              "         [3.49000e+02, 2.62000e+02, 4.39000e+02, 6.24000e+02, 8.82934e-01, 5.00000e+00],\n",
              "         [2.79000e+02, 2.52000e+02, 3.10000e+02, 2.82000e+02, 8.78311e-01, 0.00000e+00],\n",
              "         [5.96000e+02, 3.23000e+02, 6.38000e+02, 5.01000e+02, 8.68262e-01, 5.00000e+00],\n",
              "         [1.25000e+02, 3.28000e+02, 1.86000e+02, 4.43000e+02, 8.62605e-01, 7.00000e+00],\n",
              "         [8.00000e+01, 2.28000e+02, 1.31000e+02, 2.83000e+02, 8.57955e-01, 0.00000e+00],\n",
              "         [2.60000e+02, 2.49000e+02, 3.50000e+02, 6.22000e+02, 8.51719e-01, 5.00000e+00],\n",
              "         [2.31000e+02, 2.40000e+02, 2.74000e+02, 2.74000e+02, 8.41867e-01, 0.00000e+00],\n",
              "         [3.60000e+02, 3.21000e+02, 4.23000e+02, 4.39000e+02, 8.38485e-01, 7.00000e+00],\n",
              "         [3.80000e+02, 2.65000e+02, 4.10000e+02, 2.93000e+02, 8.20069e-01, 0.00000e+00],\n",
              "         [4.82000e+02, 2.85000e+02, 5.07000e+02, 3.08000e+02, 7.74698e-01, 0.00000e+00],\n",
              "         [4.30000e+02, 2.75000e+02, 4.58000e+02, 3.02000e+02, 7.61628e-01, 0.00000e+00],\n",
              "         [2.50000e+01, 2.24000e+02, 1.64000e+02, 6.40000e+02, 7.59297e-01, 5.00000e+00],\n",
              "         [1.43000e+02, 2.69000e+02, 1.70000e+02, 2.96000e+02, 7.48005e-01, 0.00000e+00],\n",
              "         [4.96000e+02, 3.24000e+02, 5.65000e+02, 4.48000e+02, 7.35409e-01, 7.00000e+00],\n",
              "         [5.22000e+02, 2.63000e+02, 5.55000e+02, 2.92000e+02, 6.97749e-01, 0.00000e+00],\n",
              "         [4.42000e+02, 3.23000e+02, 4.81000e+02, 4.31000e+02, 6.85288e-01, 7.00000e+00],\n",
              "         [2.61000e+02, 3.05000e+02, 3.33000e+02, 4.65000e+02, 6.50935e-01, 7.00000e+00],\n",
              "         [2.08000e+02, 3.01000e+02, 2.70000e+02, 4.73000e+02, 6.24009e-01, 7.00000e+00],\n",
              "         [4.21000e+02, 2.78000e+02, 4.90000e+02, 5.85000e+02, 6.08484e-01, 5.00000e+00],\n",
              "         [3.81000e+02, 2.99000e+02, 3.99000e+02, 3.18000e+02, 5.87890e-01, 3.00000e+00],\n",
              "         [4.16000e+02, 3.24000e+02, 4.50000e+02, 4.21000e+02, 5.49659e-01, 7.00000e+00],\n",
              "         [1.96000e+02, 2.49000e+02, 2.92000e+02, 6.40000e+02, 5.27718e-01, 5.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([18, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[2.15000e+02, 4.14000e+02, 2.63000e+02, 5.15000e+02, 9.61216e-01, 7.00000e+00],\n",
              "         [4.21000e+02, 4.21000e+02, 4.97000e+02, 6.06000e+02, 9.44242e-01, 7.00000e+00],\n",
              "         [3.10000e+02, 4.58000e+02, 4.00000e+02, 6.18000e+02, 9.23801e-01, 7.00000e+00],\n",
              "         [1.51000e+02, 4.06000e+02, 2.02000e+02, 4.65000e+02, 8.93529e-01, 0.00000e+00],\n",
              "         [1.24000e+02, 4.80000e+02, 2.08000e+02, 6.32000e+02, 8.85229e-01, 7.00000e+00],\n",
              "         [1.03000e+02, 4.28000e+02, 1.51000e+02, 5.64000e+02, 8.80225e-01, 7.00000e+00],\n",
              "         [2.03000e+02, 3.74000e+02, 2.76000e+02, 6.38000e+02, 8.77416e-01, 5.00000e+00],\n",
              "         [2.91000e+02, 3.94000e+02, 4.14000e+02, 6.40000e+02, 8.41039e-01, 5.00000e+00],\n",
              "         [3.36000e+02, 3.90000e+02, 3.79000e+02, 4.36000e+02, 8.38151e-01, 0.00000e+00],\n",
              "         [1.23000e+02, 3.67000e+02, 1.67000e+02, 4.08000e+02, 8.29939e-01, 0.00000e+00],\n",
              "         [1.04000e+02, 3.64000e+02, 1.67000e+02, 6.40000e+02, 8.15201e-01, 5.00000e+00],\n",
              "         [2.99000e+02, 4.00000e+02, 3.32000e+02, 4.40000e+02, 7.88754e-01, 0.00000e+00],\n",
              "         [2.85000e+02, 4.53000e+02, 3.35000e+02, 5.73000e+02, 7.81460e-01, 7.00000e+00],\n",
              "         [4.08000e+02, 3.57000e+02, 5.17000e+02, 6.40000e+02, 7.72338e-01, 5.00000e+00],\n",
              "         [2.78000e+02, 3.97000e+02, 3.52000e+02, 6.40000e+02, 7.46937e-01, 5.00000e+00],\n",
              "         [2.37000e+02, 3.75000e+02, 2.62000e+02, 3.99000e+02, 7.33273e-01, 0.00000e+00],\n",
              "         [1.16000e+02, 4.02000e+02, 2.25000e+02, 6.40000e+02, 7.30720e-01, 5.00000e+00],\n",
              "         [4.22000e+02, 3.59000e+02, 4.66000e+02, 3.96000e+02, 5.79357e-01, 0.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 88.00000, 354.00000, 123.00000, 503.00000,   0.71620,   5.00000],\n",
              "         [ 97.00000, 360.00000, 129.00000, 504.00000,   0.66329,   5.00000],\n",
              "         [ 93.00000, 380.00000, 112.00000, 422.00000,   0.62014,   7.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[167.00000,  68.00000, 358.00000, 558.00000,   0.84095,   5.00000],\n",
              "         [273.00000,  79.00000, 337.00000, 145.00000,   0.65259,   2.00000],\n",
              "         [225.00000, 146.00000, 312.00000, 328.00000,   0.61749,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 20.00000, 345.00000,  97.00000, 440.00000,   0.67457,   7.00000],\n",
              "         [ 16.00000, 312.00000, 105.00000, 549.00000,   0.57594,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[258.00000, 283.00000, 379.00000, 438.00000,   0.83955,   4.00000],\n",
              "         [162.00000, 129.00000, 458.00000, 582.00000,   0.80759,   5.00000],\n",
              "         [297.00000, 137.00000, 378.00000, 215.00000,   0.72805,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[2.94000e+02, 0.00000e+00, 6.39000e+02, 5.84000e+02, 7.84833e-01, 5.00000e+00],\n",
              "         [1.00000e+01, 0.00000e+00, 2.75000e+02, 1.00000e+02, 5.37874e-01, 5.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[294.00000, 242.00000, 495.00000, 524.00000,   0.70916,   6.00000],\n",
              "         [156.00000, 265.00000, 244.00000, 473.00000,   0.52524,   6.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000,  82.00000, 640.00000, 639.00000,   0.96368,   5.00000],\n",
              "         [162.00000,  95.00000, 508.00000, 201.00000,   0.90448,   2.00000],\n",
              "         [186.00000, 247.00000, 521.00000, 423.00000,   0.88988,   1.00000],\n",
              "         [  7.00000, 415.00000, 637.00000, 640.00000,   0.70407,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000,  95.00000, 640.00000, 639.00000,   0.95678,   5.00000],\n",
              "         [143.00000, 234.00000, 477.00000, 423.00000,   0.91794,   1.00000],\n",
              "         [153.00000, 111.00000, 500.00000, 224.00000,   0.86551,   2.00000],\n",
              "         [ 41.00000, 405.00000, 623.00000, 640.00000,   0.79885,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  1.00000, 101.00000, 640.00000, 640.00000,   0.95023,   5.00000],\n",
              "         [152.00000, 120.00000, 465.00000, 228.00000,   0.92238,   2.00000],\n",
              "         [ 31.00000, 410.00000, 625.00000, 640.00000,   0.88738,   4.00000],\n",
              "         [169.00000, 262.00000, 471.00000, 441.00000,   0.87602,   1.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000,  93.00000, 638.00000, 632.00000,   0.94467,   5.00000],\n",
              "         [ 45.00000, 257.00000, 373.00000, 442.00000,   0.91022,   1.00000],\n",
              "         [ 19.00000, 105.00000, 458.00000, 228.00000,   0.84870,   2.00000],\n",
              "         [  0.00000, 372.00000, 621.00000, 630.00000,   0.82663,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000,  84.00000, 640.00000, 639.00000,   0.96421,   5.00000],\n",
              "         [104.00000, 267.00000, 433.00000, 441.00000,   0.94095,   1.00000],\n",
              "         [  2.00000, 388.00000, 630.00000, 639.00000,   0.79041,   4.00000],\n",
              "         [ 65.00000,  99.00000, 479.00000, 238.00000,   0.71981,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000, 114.00000, 640.00000, 640.00000,   0.93851,   5.00000],\n",
              "         [ 86.00000, 299.00000, 385.00000, 469.00000,   0.91710,   1.00000],\n",
              "         [  7.00000, 422.00000, 587.00000, 640.00000,   0.86256,   4.00000],\n",
              "         [138.00000, 148.00000, 590.00000, 329.00000,   0.85321,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([40, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[6.80000e+01, 2.69000e+02, 1.21000e+02, 3.71000e+02, 9.56066e-01, 7.00000e+00],\n",
              "         [5.17000e+02, 2.77000e+02, 5.66000e+02, 3.76000e+02, 9.45278e-01, 7.00000e+00],\n",
              "         [2.66000e+02, 2.59000e+02, 3.20000e+02, 3.50000e+02, 9.22682e-01, 7.00000e+00],\n",
              "         [1.14000e+02, 2.63000e+02, 1.65000e+02, 3.59000e+02, 8.87731e-01, 7.00000e+00],\n",
              "         [6.30000e+01, 2.26000e+02, 1.26000e+02, 4.52000e+02, 8.50840e-01, 5.00000e+00],\n",
              "         [4.25000e+02, 2.50000e+02, 4.74000e+02, 3.51000e+02, 8.39326e-01, 7.00000e+00],\n",
              "         [5.03000e+02, 2.27000e+02, 5.74000e+02, 4.97000e+02, 8.33878e-01, 5.00000e+00],\n",
              "         [1.82000e+02, 2.57000e+02, 2.17000e+02, 3.47000e+02, 8.19102e-01, 7.00000e+00],\n",
              "         [3.80000e+02, 2.58000e+02, 4.34000e+02, 3.52000e+02, 7.91581e-01, 7.00000e+00],\n",
              "         [3.28000e+02, 2.69000e+02, 3.77000e+02, 3.52000e+02, 7.79627e-01, 7.00000e+00],\n",
              "         [3.70000e+02, 2.33000e+02, 4.17000e+02, 4.51000e+02, 7.74976e-01, 5.00000e+00],\n",
              "         [4.64000e+02, 2.76000e+02, 5.16000e+02, 3.78000e+02, 7.64259e-01, 7.00000e+00],\n",
              "         [3.68000e+02, 2.52000e+02, 4.04000e+02, 3.40000e+02, 7.60578e-01, 7.00000e+00],\n",
              "         [3.18000e+02, 2.18000e+02, 3.89000e+02, 4.61000e+02, 7.43793e-01, 5.00000e+00],\n",
              "         [1.16000e+02, 2.25000e+02, 1.79000e+02, 4.58000e+02, 7.25480e-01, 5.00000e+00],\n",
              "         [1.74000e+02, 2.29000e+02, 1.97000e+02, 2.55000e+02, 7.14061e-01, 0.00000e+00],\n",
              "         [3.03000e+02, 2.46000e+02, 3.41000e+02, 3.45000e+02, 7.13816e-01, 7.00000e+00],\n",
              "         [4.18000e+02, 2.10000e+02, 4.69000e+02, 4.56000e+02, 7.12415e-01, 5.00000e+00],\n",
              "         [2.16000e+02, 2.58000e+02, 2.70000e+02, 3.38000e+02, 7.00696e-01, 7.00000e+00],\n",
              "         [9.80000e+01, 2.05000e+02, 1.19000e+02, 2.26000e+02, 6.96087e-01, 0.00000e+00],\n",
              "         [4.78000e+02, 2.35000e+02, 5.05000e+02, 2.60000e+02, 6.82462e-01, 0.00000e+00],\n",
              "         [8.00000e+01, 2.30000e+02, 1.06000e+02, 2.54000e+02, 6.76287e-01, 0.00000e+00],\n",
              "         [3.76000e+02, 2.54000e+02, 4.23000e+02, 3.48000e+02, 6.48058e-01, 7.00000e+00],\n",
              "         [2.09000e+02, 2.16000e+02, 2.72000e+02, 4.51000e+02, 6.38895e-01, 5.00000e+00],\n",
              "         [1.32000e+02, 2.35000e+02, 1.56000e+02, 2.58000e+02, 6.38888e-01, 0.00000e+00],\n",
              "         [5.28000e+02, 2.23000e+02, 5.52000e+02, 2.49000e+02, 6.29596e-01, 0.00000e+00],\n",
              "         [4.93000e+02, 1.95000e+02, 5.17000e+02, 2.21000e+02, 6.19061e-01, 0.00000e+00],\n",
              "         [1.87000e+02, 2.54000e+02, 2.27000e+02, 3.46000e+02, 6.09327e-01, 7.00000e+00],\n",
              "         [1.48000e+02, 2.22000e+02, 1.98000e+02, 4.55000e+02, 6.01733e-01, 5.00000e+00],\n",
              "         [1.52000e+02, 2.57000e+02, 1.85000e+02, 3.51000e+02, 5.96372e-01, 7.00000e+00],\n",
              "         [2.02000e+02, 2.09000e+02, 2.24000e+02, 2.31000e+02, 5.81095e-01, 0.00000e+00],\n",
              "         [2.60000e+02, 2.19000e+02, 3.28000e+02, 4.57000e+02, 5.74982e-01, 5.00000e+00],\n",
              "         [3.11000e+02, 2.45000e+02, 3.41000e+02, 3.26000e+02, 5.73763e-01, 7.00000e+00],\n",
              "         [1.85000e+02, 2.15000e+02, 2.26000e+02, 4.53000e+02, 5.65332e-01, 5.00000e+00],\n",
              "         [4.57000e+02, 2.15000e+02, 5.21000e+02, 4.81000e+02, 5.42931e-01, 5.00000e+00],\n",
              "         [3.79000e+02, 2.28000e+02, 4.37000e+02, 4.49000e+02, 5.30394e-01, 5.00000e+00],\n",
              "         [1.97000e+02, 2.13000e+02, 2.34000e+02, 4.50000e+02, 5.24871e-01, 5.00000e+00],\n",
              "         [1.56000e+02, 2.19000e+02, 2.09000e+02, 4.55000e+02, 5.24809e-01, 5.00000e+00],\n",
              "         [2.27000e+02, 2.26000e+02, 2.75000e+02, 4.47000e+02, 5.14765e-01, 5.00000e+00],\n",
              "         [5.03000e+02, 2.55000e+02, 5.27000e+02, 3.43000e+02, 5.11998e-01, 7.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([17, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[4.02000e+02, 3.12000e+02, 4.78000e+02, 3.83000e+02, 8.17464e-01, 0.00000e+00],\n",
              "         [5.33000e+02, 3.71000e+02, 5.95000e+02, 4.20000e+02, 8.12775e-01, 0.00000e+00],\n",
              "         [2.61000e+02, 0.00000e+00, 4.04000e+02, 1.04000e+02, 8.03132e-01, 0.00000e+00],\n",
              "         [4.83000e+02, 3.46000e+02, 5.32000e+02, 3.93000e+02, 7.90522e-01, 0.00000e+00],\n",
              "         [0.00000e+00, 2.53000e+02, 2.62000e+02, 6.40000e+02, 7.71712e-01, 5.00000e+00],\n",
              "         [5.88000e+02, 3.66000e+02, 6.40000e+02, 4.23000e+02, 7.61975e-01, 3.00000e+00],\n",
              "         [4.00000e+00, 1.00000e+00, 2.71000e+02, 2.55000e+02, 7.47693e-01, 5.00000e+00],\n",
              "         [5.79000e+02, 2.55000e+02, 6.39000e+02, 3.37000e+02, 7.35107e-01, 0.00000e+00],\n",
              "         [2.62000e+02, 2.96000e+02, 4.99000e+02, 6.40000e+02, 7.01974e-01, 5.00000e+00],\n",
              "         [3.06000e+02, 2.52000e+02, 3.71000e+02, 2.96000e+02, 6.92469e-01, 0.00000e+00],\n",
              "         [3.39000e+02, 3.01000e+02, 6.40000e+02, 6.40000e+02, 6.87175e-01, 5.00000e+00],\n",
              "         [3.51000e+02, 3.08000e+02, 4.00000e+02, 3.51000e+02, 6.74183e-01, 0.00000e+00],\n",
              "         [1.13000e+02, 0.00000e+00, 2.65000e+02, 1.85000e+02, 6.62893e-01, 4.00000e+00],\n",
              "         [3.04000e+02, 3.16000e+02, 3.47000e+02, 3.58000e+02, 6.27370e-01, 3.00000e+00],\n",
              "         [2.58000e+02, 2.53000e+02, 4.04000e+02, 6.39000e+02, 5.61892e-01, 5.00000e+00],\n",
              "         [3.19000e+02, 4.22000e+02, 4.52000e+02, 6.40000e+02, 5.59657e-01, 4.00000e+00],\n",
              "         [1.79000e+02, 2.60000e+02, 2.65000e+02, 4.25000e+02, 5.55887e-01, 4.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[210.00000, 153.00000, 321.00000, 327.00000,   0.96500,   1.00000],\n",
              "         [172.00000, 306.00000, 417.00000, 640.00000,   0.89440,   4.00000],\n",
              "         [100.00000,  51.00000, 499.00000, 640.00000,   0.84655,   5.00000],\n",
              "         [174.00000,  59.00000, 297.00000, 137.00000,   0.79595,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.82000e+02, 3.14000e+02, 4.17000e+02, 6.40000e+02, 9.14410e-01, 4.00000e+00],\n",
              "         [1.01000e+02, 1.50000e+01, 4.91000e+02, 6.40000e+02, 8.64681e-01, 5.00000e+00],\n",
              "         [2.13000e+02, 3.30000e+01, 3.79000e+02, 1.56000e+02, 8.39874e-01, 2.00000e+00],\n",
              "         [2.75000e+02, 1.67000e+02, 3.97000e+02, 3.24000e+02, 7.39364e-01, 1.00000e+00],\n",
              "         [3.04000e+02, 1.79000e+02, 3.97000e+02, 3.28000e+02, 5.72132e-01, 1.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([6, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.49000e+02, 0.00000e+00, 1.98000e+02, 4.80000e+01, 8.20986e-01, 0.00000e+00],\n",
              "         [3.60000e+01, 2.29000e+02, 1.89000e+02, 6.38000e+02, 8.01205e-01, 5.00000e+00],\n",
              "         [5.30000e+01, 3.34000e+02, 1.67000e+02, 5.96000e+02, 7.92454e-01, 4.00000e+00],\n",
              "         [8.60000e+01, 2.32000e+02, 1.40000e+02, 2.93000e+02, 7.67075e-01, 2.00000e+00],\n",
              "         [8.30000e+01, 0.00000e+00, 2.15000e+02, 5.69000e+02, 5.86074e-01, 5.00000e+00],\n",
              "         [4.47000e+02, 8.40000e+01, 4.77000e+02, 1.20000e+02, 5.20275e-01, 2.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  0.00000,   0.00000, 636.00000, 635.00000,   0.96787,   5.00000],\n",
              "         [188.00000,   0.00000, 417.00000, 110.00000,   0.95820,   2.00000],\n",
              "         [  0.00000, 379.00000, 566.00000, 633.00000,   0.91856,   4.00000],\n",
              "         [172.00000, 149.00000, 439.00000, 407.00000,   0.88008,   1.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[400.00000, 101.00000, 420.00000, 149.00000,   0.76698,   6.00000],\n",
              "         [  7.00000, 168.00000, 640.00000, 640.00000,   0.76614,   9.00000],\n",
              "         [128.00000,  97.00000, 143.00000, 130.00000,   0.73368,   6.00000],\n",
              "         [ 16.00000, 123.00000,  32.00000, 156.00000,   0.70019,   6.00000],\n",
              "         [591.00000, 236.00000, 638.00000, 328.00000,   0.66180,   6.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([6, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[6.60000e+01, 1.79000e+02, 9.80000e+01, 2.50000e+02, 7.72547e-01, 6.00000e+00],\n",
              "         [8.00000e+00, 1.70000e+01, 6.34000e+02, 6.40000e+02, 7.63737e-01, 9.00000e+00],\n",
              "         [2.92000e+02, 8.30000e+01, 3.06000e+02, 1.15000e+02, 7.23004e-01, 6.00000e+00],\n",
              "         [3.55000e+02, 7.10000e+01, 3.65000e+02, 9.90000e+01, 7.18412e-01, 6.00000e+00],\n",
              "         [4.18000e+02, 1.28000e+02, 4.46000e+02, 1.81000e+02, 5.90596e-01, 6.00000e+00],\n",
              "         [5.10000e+01, 1.03000e+02, 6.10000e+01, 1.28000e+02, 5.74961e-01, 6.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  3.00000,   2.00000, 639.00000, 640.00000,   0.82636,   9.00000],\n",
              "         [582.00000, 208.00000, 624.00000, 290.00000,   0.77727,   6.00000],\n",
              "         [317.00000, 106.00000, 352.00000, 171.00000,   0.76147,   6.00000],\n",
              "         [423.00000, 136.00000, 454.00000, 199.00000,   0.67549,   6.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 78.00000, 270.00000, 601.00000, 640.00000,   0.86227,   9.00000],\n",
              "         [173.00000, 276.00000, 205.00000, 336.00000,   0.76680,   6.00000],\n",
              "         [470.00000, 279.00000, 506.00000, 346.00000,   0.70962,   6.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[271.00000, 165.00000, 414.00000, 585.00000,   0.81423,   5.00000],\n",
              "         [289.00000, 222.00000, 383.00000, 353.00000,   0.73077,   4.00000],\n",
              "         [309.00000, 174.00000, 353.00000, 208.00000,   0.71637,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.31000e+02, 2.40000e+02, 3.11000e+02, 5.09000e+02, 8.22337e-01, 5.00000e+00],\n",
              "         [2.99000e+02, 2.00000e+00, 5.76000e+02, 3.25000e+02, 7.38650e-01, 5.00000e+00],\n",
              "         [1.44000e+02, 2.87000e+02, 2.48000e+02, 3.79000e+02, 6.11854e-01, 4.00000e+00],\n",
              "         [3.18000e+02, 4.80000e+01, 4.56000e+02, 1.45000e+02, 6.02473e-01, 4.00000e+00],\n",
              "         [2.95000e+02, 7.00000e+00, 4.86000e+02, 3.26000e+02, 5.44692e-01, 5.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[172.00000,   5.00000, 380.00000, 257.00000,   0.86761,   5.00000],\n",
              "         [237.00000,  26.00000, 372.00000, 150.00000,   0.78756,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([6, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[138.00000,  41.00000, 447.00000, 306.00000,   0.92421,   5.00000],\n",
              "         [551.00000, 163.00000, 618.00000, 203.00000,   0.79416,   2.00000],\n",
              "         [529.00000, 197.00000, 640.00000, 328.00000,   0.79312,   4.00000],\n",
              "         [481.00000, 151.00000, 640.00000, 409.00000,   0.77244,   5.00000],\n",
              "         [222.00000,  51.00000, 438.00000, 173.00000,   0.75846,   4.00000],\n",
              "         [144.00000,  35.00000, 204.00000,  84.00000,   0.68756,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  4.00000, 102.00000, 618.00000, 528.00000,   0.75403,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 15.00000, 246.00000, 346.00000, 560.00000,   0.82535,   8.00000],\n",
              "         [236.00000, 127.00000, 640.00000, 640.00000,   0.82233,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[209.00000, 205.00000, 579.00000, 628.00000,   0.87422,   8.00000],\n",
              "         [148.00000, 112.00000, 362.00000, 374.00000,   0.64665,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  3.00000,  58.00000, 621.00000, 470.00000,   0.74836,   8.00000],\n",
              "         [317.00000,  72.00000, 640.00000, 455.00000,   0.71445,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[233.00000, 217.00000, 546.00000, 638.00000,   0.91034,   8.00000],\n",
              "         [135.00000,  77.00000, 388.00000, 446.00000,   0.90504,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[161.00000,   9.00000, 406.00000, 366.00000,   0.81818,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 49.00000, 340.00000, 168.00000, 483.00000,   0.92681,   8.00000],\n",
              "         [227.00000,  92.00000, 638.00000, 603.00000,   0.83952,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 19.00000,   4.00000, 638.00000, 640.00000,   0.91221,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 89.00000, 102.00000, 578.00000, 601.00000,   0.90587,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 77.00000, 204.00000, 634.00000, 587.00000,   0.87679,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 51.00000, 102.00000, 498.00000, 625.00000,   0.86101,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 27.00000, 100.00000, 207.00000, 310.00000,   0.90830,   8.00000],\n",
              "         [317.00000,  52.00000, 576.00000, 297.00000,   0.82408,   8.00000],\n",
              "         [  5.00000, 336.00000, 627.00000, 639.00000,   0.80412,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[267.00000, 170.00000, 388.00000, 354.00000,   0.93980,   7.00000],\n",
              "         [187.00000,  55.00000, 459.00000, 637.00000,   0.88302,   5.00000],\n",
              "         [298.00000,  60.00000, 358.00000, 117.00000,   0.86484,   0.00000],\n",
              "         [308.00000, 130.00000, 351.00000, 180.00000,   0.67277,   1.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[179.00000, 186.00000, 291.00000, 368.00000,   0.94652,   7.00000],\n",
              "         [159.00000,  74.00000, 311.00000, 633.00000,   0.80702,   5.00000],\n",
              "         [190.00000,  77.00000, 247.00000, 132.00000,   0.72827,   0.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 57.00000, 393.00000, 603.00000, 580.00000,   0.93385,   9.00000],\n",
              "         [399.00000, 310.00000, 411.00000, 337.00000,   0.64397,   6.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[151.00000, 318.00000, 364.00000, 474.00000,   0.96484,   1.00000],\n",
              "         [ 18.00000, 474.00000, 460.00000, 640.00000,   0.89167,   4.00000],\n",
              "         [  0.00000, 205.00000, 613.00000, 639.00000,   0.87574,   5.00000],\n",
              "         [124.00000, 227.00000, 317.00000, 300.00000,   0.65657,   2.00000],\n",
              "         [109.00000, 223.00000, 323.00000, 318.00000,   0.65294,   2.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([8, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.54000e+02, 1.68000e+02, 2.41000e+02, 2.54000e+02, 9.12407e-01, 0.00000e+00],\n",
              "         [3.19000e+02, 2.37000e+02, 4.63000e+02, 5.70000e+02, 8.82254e-01, 7.00000e+00],\n",
              "         [2.99000e+02, 7.50000e+01, 4.78000e+02, 6.40000e+02, 8.46849e-01, 5.00000e+00],\n",
              "         [1.27000e+02, 1.67000e+02, 3.20000e+02, 6.40000e+02, 8.38168e-01, 5.00000e+00],\n",
              "         [4.02000e+02, 1.86000e+02, 4.44000e+02, 2.32000e+02, 8.00242e-01, 3.00000e+00],\n",
              "         [3.61000e+02, 8.10000e+01, 4.57000e+02, 1.65000e+02, 7.70587e-01, 0.00000e+00],\n",
              "         [1.47000e+02, 2.75000e+02, 2.71000e+02, 5.39000e+02, 5.92995e-01, 7.00000e+00],\n",
              "         [1.87000e+02, 2.66000e+02, 2.23000e+02, 2.98000e+02, 5.53633e-01, 3.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([16, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.07000e+02, 2.29000e+02, 2.28000e+02, 4.14000e+02, 9.30152e-01, 7.00000e+00],\n",
              "         [5.30000e+01, 1.98000e+02, 1.27000e+02, 4.37000e+02, 8.60034e-01, 5.00000e+00],\n",
              "         [4.02000e+02, 2.47000e+02, 4.35000e+02, 3.16000e+02, 8.47057e-01, 7.00000e+00],\n",
              "         [1.94000e+02, 1.91000e+02, 3.27000e+02, 6.37000e+02, 8.35757e-01, 5.00000e+00],\n",
              "         [9.50000e+01, 1.39000e+02, 2.43000e+02, 6.40000e+02, 8.33139e-01, 5.00000e+00],\n",
              "         [2.99000e+02, 2.14000e+02, 3.64000e+02, 4.28000e+02, 8.31021e-01, 5.00000e+00],\n",
              "         [1.71000e+02, 1.40000e+02, 2.19000e+02, 1.91000e+02, 8.20764e-01, 0.00000e+00],\n",
              "         [6.30000e+01, 2.32000e+02, 1.09000e+02, 3.16000e+02, 8.20631e-01, 7.00000e+00],\n",
              "         [3.19000e+02, 2.21000e+02, 3.41000e+02, 2.42000e+02, 7.79034e-01, 0.00000e+00],\n",
              "         [2.44000e+02, 1.55000e+02, 2.93000e+02, 2.07000e+02, 7.70227e-01, 0.00000e+00],\n",
              "         [4.33000e+02, 2.49000e+02, 4.66000e+02, 3.09000e+02, 7.69908e-01, 7.00000e+00],\n",
              "         [3.16000e+02, 2.47000e+02, 3.52000e+02, 3.25000e+02, 7.47693e-01, 7.00000e+00],\n",
              "         [2.15000e+02, 2.47000e+02, 3.20000e+02, 3.80000e+02, 7.16209e-01, 7.00000e+00],\n",
              "         [3.96000e+02, 2.17000e+02, 4.47000e+02, 4.21000e+02, 6.66822e-01, 5.00000e+00],\n",
              "         [1.84000e+02, 2.03000e+02, 2.07000e+02, 2.30000e+02, 5.84394e-01, 3.00000e+00],\n",
              "         [9.50000e+01, 2.01000e+02, 1.23000e+02, 2.31000e+02, 5.31164e-01, 0.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([16, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[3.17000e+02, 4.00000e+01, 3.64000e+02, 9.50000e+01, 8.32344e-01, 0.00000e+00],\n",
              "         [5.00000e+00, 1.47000e+02, 6.50000e+01, 2.55000e+02, 8.26735e-01, 7.00000e+00],\n",
              "         [5.23000e+02, 0.00000e+00, 6.40000e+02, 6.38000e+02, 7.97513e-01, 5.00000e+00],\n",
              "         [0.00000e+00, 8.40000e+01, 8.30000e+01, 4.45000e+02, 7.96071e-01, 5.00000e+00],\n",
              "         [5.90000e+01, 1.37000e+02, 1.36000e+02, 2.74000e+02, 7.80568e-01, 7.00000e+00],\n",
              "         [1.94000e+02, 3.80000e+01, 3.16000e+02, 5.26000e+02, 7.79904e-01, 5.00000e+00],\n",
              "         [2.75000e+02, 4.10000e+01, 3.95000e+02, 6.37000e+02, 7.59518e-01, 5.00000e+00],\n",
              "         [2.20000e+02, 1.18000e+02, 3.05000e+02, 3.06000e+02, 7.41646e-01, 7.00000e+00],\n",
              "         [1.31000e+02, 9.20000e+01, 2.15000e+02, 4.97000e+02, 6.82352e-01, 5.00000e+00],\n",
              "         [4.38000e+02, 1.04000e+02, 4.70000e+02, 1.43000e+02, 6.81095e-01, 0.00000e+00],\n",
              "         [1.65000e+02, 9.40000e+01, 2.02000e+02, 1.29000e+02, 6.66562e-01, 0.00000e+00],\n",
              "         [1.48000e+02, 1.74000e+02, 1.97000e+02, 2.78000e+02, 6.09470e-01, 7.00000e+00],\n",
              "         [3.99000e+02, 7.90000e+01, 5.00000e+02, 5.40000e+02, 6.09383e-01, 5.00000e+00],\n",
              "         [8.80000e+01, 8.10000e+01, 1.15000e+02, 1.07000e+02, 5.59491e-01, 0.00000e+00],\n",
              "         [4.10000e+01, 8.10000e+01, 1.38000e+02, 4.64000e+02, 5.34348e-01, 5.00000e+00],\n",
              "         [2.53000e+02, 3.90000e+01, 2.93000e+02, 7.00000e+01, 5.02483e-01, 0.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[2.35000e+02, 1.20000e+02, 3.48000e+02, 5.51000e+02, 7.81914e-01, 5.00000e+00],\n",
              "         [3.79000e+02, 1.99000e+02, 4.10000e+02, 2.73000e+02, 5.84531e-01, 0.00000e+00],\n",
              "         [2.58000e+02, 1.25000e+02, 2.97000e+02, 1.70000e+02, 5.37474e-01, 0.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[123.00000,   0.00000, 353.00000, 551.00000,   0.80157,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[2.28000e+02, 6.90000e+01, 6.32000e+02, 5.50000e+02, 8.46893e-01, 8.00000e+00],\n",
              "         [3.21000e+02, 1.89000e+02, 3.90000e+02, 4.45000e+02, 6.34267e-01, 5.00000e+00],\n",
              "         [3.51000e+02, 1.90000e+02, 3.79000e+02, 2.25000e+02, 5.57224e-01, 2.00000e+00],\n",
              "         [3.39000e+02, 2.41000e+02, 3.79000e+02, 3.20000e+02, 5.30672e-01, 4.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[183.00000, 306.00000, 419.00000, 490.00000,   0.97133,   8.00000],\n",
              "         [270.00000,  88.00000, 633.00000, 383.00000,   0.90450,   8.00000],\n",
              "         [ 13.00000, 258.00000, 164.00000, 364.00000,   0.79596,   8.00000],\n",
              "         [503.00000, 229.00000, 530.00000, 280.00000,   0.76578,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[352.00000, 115.00000, 490.00000, 330.00000,   0.91243,   7.00000],\n",
              "         [337.00000,  96.00000, 513.00000, 634.00000,   0.82469,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([4, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.41000e+02, 6.10000e+01, 3.92000e+02, 6.37000e+02, 8.25650e-01, 5.00000e+00],\n",
              "         [2.48000e+02, 6.80000e+01, 3.10000e+02, 1.60000e+02, 7.90702e-01, 0.00000e+00],\n",
              "         [1.95000e+02, 2.17000e+02, 3.51000e+02, 6.40000e+02, 7.12964e-01, 4.00000e+00],\n",
              "         [2.08000e+02, 2.09000e+02, 3.84000e+02, 5.69000e+02, 5.21781e-01, 4.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  2.00000,   6.00000, 636.00000, 626.00000,   0.91029,   8.00000],\n",
              "         [283.00000, 247.00000, 303.00000, 288.00000,   0.82133,   7.00000],\n",
              "         [275.00000, 224.00000, 312.00000, 367.00000,   0.74292,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  1.00000,   0.00000, 593.00000, 626.00000,   0.88361,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 70.00000, 453.00000,  98.00000, 487.00000,   0.76856,   9.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[277.00000,  86.00000, 640.00000, 608.00000,   0.89401,   8.00000],\n",
              "         [ 27.00000, 156.00000,  72.00000, 197.00000,   0.84884,   9.00000],\n",
              "         [ 96.00000, 178.00000, 128.00000, 207.00000,   0.77793,   9.00000],\n",
              "         [514.00000, 346.00000, 546.00000, 435.00000,   0.68419,   5.00000],\n",
              "         [186.00000, 184.00000, 220.00000, 220.00000,   0.65486,   9.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[152.00000,   0.00000, 388.00000, 615.00000,   0.85859,   5.00000],\n",
              "         [196.00000,   0.00000, 350.00000, 225.00000,   0.79886,   4.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 81.00000, 265.00000, 545.00000, 564.00000,   0.84483,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[129.00000, 113.00000, 493.00000, 540.00000,   0.80306,   8.00000],\n",
              "         [519.00000, 306.00000, 640.00000, 580.00000,   0.64516,   8.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([7, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[2.08000e+02, 2.24000e+02, 2.49000e+02, 3.35000e+02, 8.66585e-01, 7.00000e+00],\n",
              "         [3.69000e+02, 2.83000e+02, 4.28000e+02, 3.41000e+02, 8.03639e-01, 9.00000e+00],\n",
              "         [2.90000e+02, 1.82000e+02, 3.53000e+02, 3.93000e+02, 7.40975e-01, 7.00000e+00],\n",
              "         [1.98000e+02, 1.62000e+02, 2.61000e+02, 5.09000e+02, 7.11947e-01, 5.00000e+00],\n",
              "         [2.71000e+02, 4.70000e+01, 3.73000e+02, 6.17000e+02, 5.99897e-01, 5.00000e+00],\n",
              "         [2.27000e+02, 1.72000e+02, 2.54000e+02, 2.17000e+02, 5.98320e-01, 0.00000e+00],\n",
              "         [3.11000e+02, 1.41000e+02, 3.37000e+02, 1.73000e+02, 5.94350e-01, 0.00000e+00]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[ 47.00000,   0.00000, 293.00000, 625.00000,   0.88699,   5.00000],\n",
              "         [ 87.00000,   1.00000, 250.00000, 218.00000,   0.66611,   7.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([2, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[  3.00000,   0.00000, 158.00000, 257.00000,   0.94052,   7.00000],\n",
              "         [  0.00000,   0.00000, 186.00000, 597.00000,   0.87909,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([1, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[192.00000,   0.00000, 639.00000, 512.00000,   0.88277,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([5, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[198.00000,  28.00000, 378.00000, 473.00000,   0.95800,   0.00000],\n",
              "         [199.00000,  19.00000, 640.00000, 551.00000,   0.88753,   5.00000],\n",
              "         [430.00000, 218.00000, 640.00000, 548.00000,   0.87541,   7.00000],\n",
              "         [370.00000, 296.00000, 450.00000, 466.00000,   0.76942,   3.00000],\n",
              "         [330.00000,  12.00000, 640.00000, 551.00000,   0.74982,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([0, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([], device='cuda:0', size=(0, 6)),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([3, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[253.00000,   1.00000, 369.00000, 120.00000,   0.93341,   0.00000],\n",
              "         [194.00000, 176.00000, 462.00000, 626.00000,   0.92590,   7.00000],\n",
              "         [149.00000,   3.00000, 481.00000, 640.00000,   0.88583,   5.00000]], device='cuda:0'),\n",
              " Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n",
              " type: <class 'torch.Tensor'>\n",
              " shape: torch.Size([6, 6])\n",
              " dtype: torch.float32\n",
              "  + tensor([[1.41000e+02, 2.12000e+02, 2.93000e+02, 5.16000e+02, 9.62593e-01, 7.00000e+00],\n",
              "         [1.31000e+02, 1.05000e+02, 3.79000e+02, 6.40000e+02, 8.64459e-01, 5.00000e+00],\n",
              "         [2.02000e+02, 1.00000e+02, 2.75000e+02, 1.79000e+02, 8.16501e-01, 0.00000e+00],\n",
              "         [1.00000e+00, 1.80000e+02, 1.27000e+02, 4.41000e+02, 7.76756e-01, 9.00000e+00],\n",
              "         [2.37000e+02, 1.87000e+02, 2.67000e+02, 2.27000e+02, 5.99818e-01, 3.00000e+00],\n",
              "         [2.89000e+02, 1.63000e+02, 6.40000e+02, 6.39000e+02, 5.60546e-01, 9.00000e+00]], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}